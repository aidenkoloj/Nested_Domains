None
host: login-4
Building DAG of jobs...
Need to rerun job make_uniref50_dictionary because of missing output required by all.
Need to rerun job all because job make_uniref50_dictionary has to be rerun.
outputs/uniprot_to_uniref50_mapping.pkl: True 0
: False 1
shared_storage_local_copies: True
remote_exec: False
Submitting maximum 100 job(s) over 1.0 second(s).
SLURM run ID: 2d895b64-5082-484a-8987-9f51c38064bc
Using shell: /usr/bin/bash
Provided remote nodes: 1
Job stats:
job                         count
------------------------  -------
all                             1
make_uniref50_dictionary        1
total                           2

Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 1, '_job_count': 9223372036854775807}
Ready jobs: 1
Select jobs to execute...
Selecting jobs to run using greedy solver.
Selected jobs: 1
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 0, '_job_count': 100}
Execute 1 jobs...
[Mon Jul  7 17:52:06 2025]
rule make_uniref50_dictionary:
    input: /home/gridsan/akolodziej/solab_shared/uniref50/uniref50.xml.gz
    output: outputs/uniprot_to_uniref50_mapping.pkl
    log: logs/uniref50_dictionary.log
    jobid: 1
    reason: Missing output files: outputs/uniprot_to_uniref50_mapping.pkl
    resources: tmpdir=<TBD>, mem_mb=64000, mem_mib=61036, time_min=1200, cpus_per_task=1
Shell command: python scripts/uniref50_to_dict.py /home/gridsan/akolodziej/solab_shared/uniref50/uniref50.xml.gz outputs/uniprot_to_uniref50_mapping.pkl &> logs/uniref50_dictionary.log
No SLURM account given, trying to guess.
Unable to guess SLURM account. Trying to proceed without.
No wall time information given. This might or might not work on your cluster. If not, specify the resource runtime in your rule or as a reasonable default via --default-resources.
General args: ['--force', '--target-files-omit-workdir-adjustment', '', '--max-inventory-time 0', '--nocolor', '--notemp', '--no-hooks', '--nolock', '--ignore-incomplete', '', '--verbose ', '--rerun-triggers software-env mtime params code input', '', '', '', '', "--conda-frontend 'conda'", '', '', '', '', '', '--shared-fs-usage sources source-cache storage-local-copies persistence software-deployment input-output', '', "--wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/'", '', '', '', '--printshellcmds ', '', '--latency-wait 5', "--scheduler 'ilp'", '', '--local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl', "--scheduler-solver-path '/home/gridsan/akolodziej/.conda/envs/snakemake/bin'", '', '', '', '', '', '', '--default-resources base64//dG1wZGlyPXN5c3RlbV90bXBkaXI=', '']
sbatch call: sbatch --parsable --job-name 2d895b64-5082-484a-8987-9f51c38064bc --output "/home/gridsan/akolodziej/01_insert_domains/.snakemake/slurm_logs/rule_make_uniref50_dictionary/%j.log" --export=ALL --comment "rule_make_uniref50_dictionary"   -p xeon-g6-volta --mem 64000 --ntasks=1 --cpus-per-task=1 -D '/home/gridsan/akolodziej/01_insert_domains' --wrap="/home/gridsan/akolodziej/.conda/envs/snakemake/bin/python3.12 -m snakemake --snakefile '/home/gridsan/akolodziej/01_insert_domains/Snakefile' --target-jobs 'make_uniref50_dictionary:' --allowed-rules make_uniref50_dictionary --cores 'all' --attempt 1 --force-use-threads  --wait-for-files '/home/gridsan/akolodziej/01_insert_domains/.snakemake/tmp.b6k1yolh' '/home/gridsan/akolodziej/solab_shared/uniref50/uniref50.xml.gz' --force --target-files-omit-workdir-adjustment --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --verbose  --rerun-triggers software-env mtime params code input --conda-frontend 'conda' --shared-fs-usage sources source-cache storage-local-copies persistence software-deployment input-output --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 5 --scheduler 'ilp' --local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl --scheduler-solver-path '/home/gridsan/akolodziej/.conda/envs/snakemake/bin' --default-resources base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= --executor slurm-jobstep --jobs 1 --mode 'remote'"
Job 1 has been submitted with SLURM jobid 1140992 (log: /home/gridsan/akolodziej/01_insert_domains/.snakemake/slurm_logs/rule_make_uniref50_dictionary/1140992.log).
Waiting for running jobs to complete.
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.10956239700317383 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.10003495216369629 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.09978055953979492 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.11998939514160156 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.10018205642700195 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.11013531684875488 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.10932397842407227 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T17:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.09993743896484375 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T18:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.11006736755371094 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T18:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.11392927169799805 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T18:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.10025191307067871 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T18:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.1101982593536377 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Checking the status of 1 active jobs with 5 attempts.
The job status was queried with command: sacct -X --parsable2 --clusters all --noheader --format=JobIdRaw,State --starttime 2025-07-05T18:00 --endtime now --name 2d895b64-5082-484a-8987-9f51c38064bc
It took: 0.12024116516113281 seconds
The output is:
'1140992|RUNNING
'

status_of_jobs after sacct is: {'1140992': 'RUNNING'}
active_jobs_ids_with_current_sacct_status are: {'1140992'}
active_jobs_seen_by_sacct are: {'1140992'}
missing_sacct_status are: set()
Terminating processes on user request, this might take some time.
Cleaning up log files older than 10 day(s).
Complete log(s): /home/gridsan/akolodziej/01_insert_domains/.snakemake/log/2025-07-07T175206.393896.snakemake.log
unlocking
removing lock
removing lock
removed all locks
Full Traceback (most recent call last):
  File "/home/gridsan/akolodziej/.conda/envs/snakemake/lib/python3.12/site-packages/snakemake/cli.py", line 2164, in args_to_api
    dag_api.execute_workflow(
  File "/home/gridsan/akolodziej/.conda/envs/snakemake/lib/python3.12/site-packages/snakemake/api.py", line 603, in execute_workflow
    workflow.execute(
  File "/home/gridsan/akolodziej/.conda/envs/snakemake/lib/python3.12/site-packages/snakemake/workflow.py", line 1451, in execute
    raise WorkflowError("At least one job did not complete successfully.")
snakemake_interface_common.exceptions.WorkflowError: At least one job did not complete successfully.

WorkflowError:
At least one job did not complete successfully.
